{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a98f9044-5156-4ed0-8e4b-f352f260f9a1",
   "metadata": {},
   "source": [
    "# LIDA - Automatic Generation of Visualizations and Infographics using Large Language Models\n",
    "\n",
    "LIDA is a library for generating data visualizations and data-faithful infographics. LIDA is grammar agnostic (will work with any programming language and visualization libraries e.g. matplotlib, seaborn, altair, d3 etc) and works with multiple large language model providers (OpenAI, PaLM, Cohere, Huggingface). Details on the components of LIDA are described in the [paper here](https://arxiv.org/abs/2303.02927). See the project page [here](https://microsoft.github.io/lida/) for updates!.\n",
    "\n",
    "\n",
    "## LIDA with OpenAI model\n",
    "This tutorial focus on the implementation with OpenAI models  \n",
    "\n",
    "\n",
    "## Getting Started | Installation\n",
    "If you intend to use lida with local huggingface models, you will need to install the `transformers` library.\n",
    "```bash\n",
    "pip install lida[transformers]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b6e7e1-7f48-41df-8480-200661a7b3b1",
   "metadata": {},
   "source": [
    "## The LIDA Python API\n",
    "\n",
    "Lida offers a manager class that exposes core functionality of the LIDA system. This tutorial will show you how to use the manager class to create visualizations based on a dataset leveraging on opensource model on hugging face.\n",
    "\n",
    "\n",
    "### Open source LLM Backends\n",
    "By default, LIDA uses the `openai` backend but in this tutorial, we will use a LLM from hugging face as the backend. First, we set up the backend with `text_gen` parameter in the `Manager` class. For a list of supported models and how to configure them, see the [llmx documentation](https://github.com/victordibia/llmx)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9edaee81-c3a8-4549-8d13-caeaa081c1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lida import Manager, TextGenerationConfig, llm\n",
    "import warnings\n",
    "\n",
    "# Ignore warnings for cleaner output\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Clear CUDA cache to release GPU memory\n",
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59fae264-6638-4fa8-a630-fa59addad77e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got to HFTextGenerator\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|████████████████████████████████████| 2/2 [00:57<00:00, 28.83s/it]\n"
     ]
    }
   ],
   "source": [
    "# Initialize Lida Manager with Hugging Face model provider\n",
    "text_gen = llm(provider=\"hf\",\n",
    "               model=\"mistralai/Mistral-7B-v0.1\",\n",
    "               device_map=\"auto\")\n",
    "\n",
    "lida_manager = Manager(text_gen=text_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90fdfd5a-4817-4b1a-ad9f-c3c22ff6f79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate summary from a CSV file\n",
    "summary = lida_manager.summarize(\"https://raw.githubusercontent.com/uwdata/draco/master/data/cars.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5288a16-ceb8-4809-8bb7-9308acf2a53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure text generation settings for goals\n",
    "textgen_config = TextGenerationConfig(n=1, temperature=0.5, model=\"Mistral-7B-v0.1\", use_cache=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd212ae2-6892-44d6-b748-ae8c6220730b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate goals based on the summary\n",
    "goals = lida_manager.goals(summary, n=2, textgen_config=textgen_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "28e9a6f2-daa7-4659-a693-3f069aa14597",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "### Goal 0\n",
       "---\n",
       "**Question:** What is the distribution of Cyl?\n",
       "\n",
       "**Visualization:** `histogram of Cyl`\n",
       "\n",
       "**Rationale:** This tells about the distribution of Cyl\n"
      ],
      "text/plain": [
       "Goal(question='What is the distribution of Cyl?', visualization='histogram of Cyl', rationale='This tells about the distribution of Cyl', index=0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "### Goal 1\n",
       "---\n",
       "**Question:** What is the distribution of Weight?\n",
       "\n",
       "**Visualization:** `histogram of Weight`\n",
       "\n",
       "**Rationale:** This tells about the distribution of Weight\n"
      ],
      "text/plain": [
       "Goal(question='What is the distribution of Weight?', visualization='histogram of Weight', rationale='This tells about the distribution of Weight', index=1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display the generated goals\n",
    "for goal in goals:\n",
    "    display(goal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0913ba51-1830-48a5-84f0-8f4f146e2b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize data using a specific library and goal\n",
    "i = 1\n",
    "library = \"seaborn\"\n",
    "textgen_config = TextGenerationConfig(n=1, temperature=0.2, use_cache=True)\n",
    "\n",
    "# Generate visualization based on the selected goal\n",
    "charts = lida_manager.visualize(summary=summary, goal=goals[i], textgen_config=textgen_config, library=library)\n",
    "\n",
    "# Display the generated visualization\n",
    "charts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86ef199-5b14-4a98-a2f4-661d137e0244",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lida_env",
   "language": "python",
   "name": "lida_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
